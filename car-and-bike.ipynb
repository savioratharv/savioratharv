{"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Network","metadata":{"id":"3DR-eO17geWu"}},{"cell_type":"markdown","source":"### Importing the libraries","metadata":{"id":"EMefrVPCg-60"}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","metadata":{"id":"sCV30xyVhFbE","execution":{"iopub.status.busy":"2022-11-07T10:48:02.150616Z","iopub.execute_input":"2022-11-07T10:48:02.151772Z","iopub.status.idle":"2022-11-07T10:48:07.739007Z","shell.execute_reply.started":"2022-11-07T10:48:02.151630Z","shell.execute_reply":"2022-11-07T10:48:07.738001Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"tf.__version__","metadata":{"id":"FIleuCAjoFD8","execution":{"iopub.status.busy":"2022-11-07T10:48:07.740935Z","iopub.execute_input":"2022-11-07T10:48:07.741836Z","iopub.status.idle":"2022-11-07T10:48:07.759147Z","shell.execute_reply.started":"2022-11-07T10:48:07.741797Z","shell.execute_reply":"2022-11-07T10:48:07.757906Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.6.4'"},"metadata":{}}]},{"cell_type":"markdown","source":"## Part 1 - Data Preprocessing","metadata":{"id":"oxQxCBWyoGPE"}},{"cell_type":"markdown","source":"### Preprocessing the Training set","metadata":{"id":"MvE-heJNo3GG"}},{"cell_type":"code","source":"import os\nos.makedirs('./test_data')","metadata":{"execution":{"iopub.status.busy":"2022-11-07T10:48:07.764009Z","iopub.execute_input":"2022-11-07T10:48:07.766974Z","iopub.status.idle":"2022-11-07T10:48:07.773227Z","shell.execute_reply.started":"2022-11-07T10:48:07.766938Z","shell.execute_reply":"2022-11-07T10:48:07.772167Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install split_folders","metadata":{"execution":{"iopub.status.busy":"2022-11-07T10:48:07.779317Z","iopub.execute_input":"2022-11-07T10:48:07.781581Z","iopub.status.idle":"2022-11-07T10:48:19.915254Z","shell.execute_reply.started":"2022-11-07T10:48:07.781547Z","shell.execute_reply":"2022-11-07T10:48:19.914117Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting split_folders\n  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split_folders\nSuccessfully installed split_folders-0.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"\nimport splitfolders # or import splitfolders\ninput_folder = \"../input/car-vs-bike-classification-dataset/Car-Bike-Dataset\"\noutput = \"./test_data\" #where you want the split datasets saved. one will be created if it does not exist or none is set\n\nsplitfolders.ratio(input_folder, output=output, seed=42, ratio=(.8, .1, .1)) # ratio of split are in order of train/val/test. You can change to whatever you want. For train/val sets only, you could do .75, .25 for example.","metadata":{"execution":{"iopub.status.busy":"2022-11-07T10:48:19.918398Z","iopub.execute_input":"2022-11-07T10:48:19.918816Z","iopub.status.idle":"2022-11-07T10:48:36.562124Z","shell.execute_reply.started":"2022-11-07T10:48:19.918751Z","shell.execute_reply":"2022-11-07T10:48:36.561115Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Copying files: 4000 files [00:16, 240.67 files/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\ntraining_set = train_datagen.flow_from_directory('../input/car-vs-bike-classification-dataset/Car-Bike-Dataset',\n                                                 target_size = (64, 64),\n                                                 batch_size = 32,\n                                                 class_mode = 'binary')","metadata":{"id":"0koUcJMJpEBD","execution":{"iopub.status.busy":"2022-11-07T10:48:36.563420Z","iopub.execute_input":"2022-11-07T10:48:36.563800Z","iopub.status.idle":"2022-11-07T10:48:37.458368Z","shell.execute_reply.started":"2022-11-07T10:48:36.563764Z","shell.execute_reply":"2022-11-07T10:48:37.457225Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 4000 images belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preprocessing the Test set","metadata":{"id":"mrCMmGw9pHys"}},{"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale = 1./255)\ntest_set = test_datagen.flow_from_directory('./test_data',\n                                            target_size = (64, 64),\n                                            batch_size = 32,\n                                            class_mode = 'binary')","metadata":{"id":"SH4WzfOhpKc3","execution":{"iopub.status.busy":"2022-11-07T10:48:37.459924Z","iopub.execute_input":"2022-11-07T10:48:37.460627Z","iopub.status.idle":"2022-11-07T10:48:37.674464Z","shell.execute_reply.started":"2022-11-07T10:48:37.460589Z","shell.execute_reply":"2022-11-07T10:48:37.673565Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 4000 images belonging to 3 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Part 2 - Building the CNN","metadata":{"id":"af8O4l90gk7B"}},{"cell_type":"markdown","source":"### Initialising the CNN","metadata":{"id":"ces1gXY2lmoX"}},{"cell_type":"code","source":"cnn = tf.keras.models.Sequential()","metadata":{"id":"SAUt4UMPlhLS","execution":{"iopub.status.busy":"2022-11-07T10:48:37.675845Z","iopub.execute_input":"2022-11-07T10:48:37.676202Z","iopub.status.idle":"2022-11-07T10:48:40.252886Z","shell.execute_reply.started":"2022-11-07T10:48:37.676176Z","shell.execute_reply":"2022-11-07T10:48:40.251841Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2022-11-07 10:48:37.757571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:37.878539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:37.879277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:37.880558: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-07 10:48:37.880823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:37.881520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:37.882191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:39.873144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:39.873962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:39.874607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-11-07 10:48:39.875200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Step 1 - Convolution","metadata":{"id":"u5YJj_XMl5LF"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))","metadata":{"id":"XPzPrMckl-hV","execution":{"iopub.status.busy":"2022-11-07T10:48:40.254282Z","iopub.execute_input":"2022-11-07T10:48:40.254945Z","iopub.status.idle":"2022-11-07T10:48:40.303631Z","shell.execute_reply.started":"2022-11-07T10:48:40.254907Z","shell.execute_reply":"2022-11-07T10:48:40.302770Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Step 2 - Pooling","metadata":{"id":"tf87FpvxmNOJ"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","metadata":{"id":"ncpqPl69mOac","execution":{"iopub.status.busy":"2022-11-07T10:48:40.308053Z","iopub.execute_input":"2022-11-07T10:48:40.310076Z","iopub.status.idle":"2022-11-07T10:48:40.319191Z","shell.execute_reply.started":"2022-11-07T10:48:40.310049Z","shell.execute_reply":"2022-11-07T10:48:40.318263Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Adding a second convolutional layer","metadata":{"id":"xaTOgD8rm4mU"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\ncnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))","metadata":{"id":"i_-FZjn_m8gk","execution":{"iopub.status.busy":"2022-11-07T10:48:40.320563Z","iopub.execute_input":"2022-11-07T10:48:40.321134Z","iopub.status.idle":"2022-11-07T10:48:40.339591Z","shell.execute_reply.started":"2022-11-07T10:48:40.321092Z","shell.execute_reply":"2022-11-07T10:48:40.338764Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Step 3 - Flattening","metadata":{"id":"tmiEuvTunKfk"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Flatten())","metadata":{"id":"6AZeOGCvnNZn","execution":{"iopub.status.busy":"2022-11-07T10:48:40.340927Z","iopub.execute_input":"2022-11-07T10:48:40.341236Z","iopub.status.idle":"2022-11-07T10:48:40.352137Z","shell.execute_reply.started":"2022-11-07T10:48:40.341204Z","shell.execute_reply":"2022-11-07T10:48:40.351106Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Step 4 - Full Connection","metadata":{"id":"dAoSECOm203v"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))","metadata":{"id":"8GtmUlLd26Nq","execution":{"iopub.status.busy":"2022-11-07T10:48:40.353340Z","iopub.execute_input":"2022-11-07T10:48:40.356395Z","iopub.status.idle":"2022-11-07T10:48:40.382449Z","shell.execute_reply.started":"2022-11-07T10:48:40.356350Z","shell.execute_reply":"2022-11-07T10:48:40.380324Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Step 5 - Output Layer","metadata":{"id":"yTldFvbX28Na"}},{"cell_type":"code","source":"cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))","metadata":{"id":"1p_Zj1Mc3Ko_","execution":{"iopub.status.busy":"2022-11-07T10:48:40.386579Z","iopub.execute_input":"2022-11-07T10:48:40.386966Z","iopub.status.idle":"2022-11-07T10:48:40.416343Z","shell.execute_reply.started":"2022-11-07T10:48:40.386934Z","shell.execute_reply":"2022-11-07T10:48:40.412306Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Part 3 - Training the CNN","metadata":{"id":"D6XkI90snSDl"}},{"cell_type":"markdown","source":"### Compiling the CNN","metadata":{"id":"vfrFQACEnc6i"}},{"cell_type":"code","source":"cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{"id":"NALksrNQpUlJ","execution":{"iopub.status.busy":"2022-11-07T10:48:40.418927Z","iopub.execute_input":"2022-11-07T10:48:40.419263Z","iopub.status.idle":"2022-11-07T10:48:40.442339Z","shell.execute_reply.started":"2022-11-07T10:48:40.419230Z","shell.execute_reply":"2022-11-07T10:48:40.441180Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Training the CNN on the Training set and evaluating it on the Test set","metadata":{"id":"ehS-v3MIpX2h"}},{"cell_type":"code","source":"cnn.fit(x = training_set, validation_data = test_set, epochs = 25)","metadata":{"id":"XUj1W4PJptta","execution":{"iopub.status.busy":"2022-11-07T10:48:40.443825Z","iopub.execute_input":"2022-11-07T10:48:40.444524Z","iopub.status.idle":"2022-11-07T11:00:37.196674Z","shell.execute_reply.started":"2022-11-07T10:48:40.444490Z","shell.execute_reply":"2022-11-07T11:00:37.195755Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2022-11-07 10:48:40.961594: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/25\n","output_type":"stream"},{"name":"stderr","text":"2022-11-07 10:48:42.693383: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":" 19/125 [===>..........................] - ETA: 11s - loss: 0.7171 - accuracy: 0.5428","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/PIL/Image.py:993: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  \"Palette images with Transparency expressed in bytes should be \"\n","output_type":"stream"},{"name":"stdout","text":"125/125 [==============================] - 35s 222ms/step - loss: 0.5051 - accuracy: 0.7340 - val_loss: 1.7808 - val_accuracy: 0.4200\nEpoch 2/25\n125/125 [==============================] - 28s 223ms/step - loss: 0.2807 - accuracy: 0.8827 - val_loss: 2.5965 - val_accuracy: 0.3750\nEpoch 3/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.2490 - accuracy: 0.9022 - val_loss: 2.5537 - val_accuracy: 0.4155\nEpoch 4/25\n125/125 [==============================] - 28s 223ms/step - loss: 0.2393 - accuracy: 0.9045 - val_loss: 3.1289 - val_accuracy: 0.3745\nEpoch 5/25\n125/125 [==============================] - 28s 226ms/step - loss: 0.2085 - accuracy: 0.9162 - val_loss: 4.0818 - val_accuracy: 0.3658\nEpoch 6/25\n125/125 [==============================] - 29s 234ms/step - loss: 0.1974 - accuracy: 0.9175 - val_loss: 2.7282 - val_accuracy: 0.4420\nEpoch 7/25\n125/125 [==============================] - 30s 243ms/step - loss: 0.1918 - accuracy: 0.9185 - val_loss: 4.5538 - val_accuracy: 0.3882\nEpoch 8/25\n125/125 [==============================] - 30s 238ms/step - loss: 0.1705 - accuracy: 0.9335 - val_loss: 3.8262 - val_accuracy: 0.4175\nEpoch 9/25\n125/125 [==============================] - 29s 229ms/step - loss: 0.1701 - accuracy: 0.9345 - val_loss: 3.5090 - val_accuracy: 0.4412\nEpoch 10/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.1498 - accuracy: 0.9408 - val_loss: 4.3533 - val_accuracy: 0.4207\nEpoch 11/25\n125/125 [==============================] - 28s 229ms/step - loss: 0.1270 - accuracy: 0.9500 - val_loss: 3.6720 - val_accuracy: 0.4557\nEpoch 12/25\n125/125 [==============================] - 28s 221ms/step - loss: 0.1411 - accuracy: 0.9395 - val_loss: 4.2515 - val_accuracy: 0.4293\nEpoch 13/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.1302 - accuracy: 0.9523 - val_loss: 4.6736 - val_accuracy: 0.4263\nEpoch 14/25\n125/125 [==============================] - 28s 229ms/step - loss: 0.1228 - accuracy: 0.9498 - val_loss: 3.3898 - val_accuracy: 0.4572\nEpoch 15/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.1144 - accuracy: 0.9580 - val_loss: 3.5386 - val_accuracy: 0.4557\nEpoch 16/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.0929 - accuracy: 0.9607 - val_loss: 5.9978 - val_accuracy: 0.4255\nEpoch 17/25\n125/125 [==============================] - 28s 227ms/step - loss: 0.1101 - accuracy: 0.9585 - val_loss: 6.9673 - val_accuracy: 0.3943\nEpoch 18/25\n125/125 [==============================] - 29s 229ms/step - loss: 0.0949 - accuracy: 0.9625 - val_loss: 4.6273 - val_accuracy: 0.4420\nEpoch 19/25\n125/125 [==============================] - 28s 224ms/step - loss: 0.0849 - accuracy: 0.9705 - val_loss: 6.1588 - val_accuracy: 0.4135\nEpoch 20/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.0801 - accuracy: 0.9680 - val_loss: 8.0492 - val_accuracy: 0.3957\nEpoch 21/25\n125/125 [==============================] - 28s 222ms/step - loss: 0.0707 - accuracy: 0.9745 - val_loss: 6.7886 - val_accuracy: 0.4297\nEpoch 22/25\n125/125 [==============================] - 28s 225ms/step - loss: 0.0735 - accuracy: 0.9735 - val_loss: 5.7453 - val_accuracy: 0.4437\nEpoch 23/25\n125/125 [==============================] - 28s 228ms/step - loss: 0.0510 - accuracy: 0.9800 - val_loss: 7.2489 - val_accuracy: 0.4338\nEpoch 24/25\n125/125 [==============================] - 28s 227ms/step - loss: 0.0592 - accuracy: 0.9768 - val_loss: 8.3533 - val_accuracy: 0.4212\nEpoch 25/25\n125/125 [==============================] - 28s 224ms/step - loss: 0.0567 - accuracy: 0.9808 - val_loss: 6.6084 - val_accuracy: 0.4425\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fab59341550>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Part 4 - Making a single prediction","metadata":{"id":"U3PZasO0006Z"}},{"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('../input/issacar/car.jfif', target_size = (64, 64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nif result[0][0] == 1:\n  prediction = 'car'\nelse:\n  prediction = 'bike'","metadata":{"id":"gsSiWEJY1BPB","execution":{"iopub.status.busy":"2022-11-07T11:20:43.570723Z","iopub.execute_input":"2022-11-07T11:20:43.571395Z","iopub.status.idle":"2022-11-07T11:20:43.616395Z","shell.execute_reply.started":"2022-11-07T11:20:43.571360Z","shell.execute_reply":"2022-11-07T11:20:43.615508Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(prediction)","metadata":{"id":"ED9KB3I54c1i","execution":{"iopub.status.busy":"2022-11-07T11:20:46.213789Z","iopub.execute_input":"2022-11-07T11:20:46.214487Z","iopub.status.idle":"2022-11-07T11:20:46.219472Z","shell.execute_reply.started":"2022-11-07T11:20:46.214451Z","shell.execute_reply":"2022-11-07T11:20:46.218432Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"car\n","output_type":"stream"}]}]}